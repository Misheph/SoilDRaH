---
title: "Data Rescue: Ares 2001"
format:
  html:
    toc: true
date: last-modified
date-format: YYYY-MMMM
bibliography:
  - Ares2001_Methods.bib
  - Ares2001.bib
authors:
  - name:
      given: Katherine
      family: Todd-Brown
    orcid: 0000-0002-3109-8130
    note: https://github.com/ktoddbrown
    affiliation:
      - ref: uf-ees
    role: 
      - Transcription
      - Review
      - Standardization

  - name:
      given: Colby
      family: Green
    affiliation:
      - ref: uf-ees
    role: Transcription
    note: https://github.com/colbyGreen1520

  - name:
      given: Savannah
      family: Scott
    affiliation:
      - ref: uf-ees
    role: Transcription
    note: https://github.com/SavaScott
      
affiliations:
  - id: uf-ees
    name: University of Florida
    department: Environmental Engineering Sciences
    city: Gainesville
    state: FL
    country: USA
    url: https://essie.ufl.edu/ees/
---

```{r setup, include=TRUE, warning=FALSE, message=FALSE, echo=FALSE}

library(tidyverse)
library(kableExtra)
library(bibtex)

methods.file <- 'Ares2001_Methods.md'
table1.file <- 'Ares2001_Table1.csv'
table3.file <- 'Ares2001_Table3.csv'
primaryCitation.file <- 'Ares2001.bib'
methodsCitation.file <- 'Ares2001_Methods.bib'
```

This documents the data transcription for @Ares2001 .
For the discussion of this data rescue see Github [issue 77](https://github.com/ktoddbrown/SoilDRaH/issues/77) .

> A. Ares and J. H. Fownes. Productivity, resource use, and competitive interactions of fraxinus uhdei in hawaii uplands. Canadian Journal of Forest Research, 31(1):132-142, [https://doi.org/10.1139/x00-156](https://doi.org/10.1139/x00-156). 2001 

# Data Summary

@Ares2001 primarily measures tree growth parameters (including litterfall) but also characterized elemental fractions of soil. They use this data to look at factors affecting a specific invasive tree growth in Hawaii including nitrogen and moisture gradients.

## Fit for purpose: HiCSC

This data is identified as a data source for the [Hawai'i Soil Organic Carbon Database](https://osf.io/hmtv6/) as part of the HiCSC.

- Location: Location region is identified and lat/lon can likely be recovered from figure 1 by regional expert.
- Soil carbon stock: Soil carbon fraction is given but not bulk density nor coarse fraction.
- Soil type: Soil order and history are identified in methods. High/low activity clay status may need inference by regional expert.
- Land use: Land use and history are clearly identified in methods.

# Tables and figures

- Table 
  1) characteristics of stands including oc percent < -- oc == organic carbon -->
  2) regression coefficients linking diameter at breast height to biomass and leaf area
  3) climate
  4) elevation vs productivity metrics
  5) fertilizer treatment vs productivity over time
  6) fertilizer vs leaf area index
  7) gradient vs plant efficiency metrics

- Figure 
  1) stand map overlayed on soil
  2) elevation vs productivity metrics
  3) nitrogen correlations
  4) light intercept vs nitrogen and water use efficiency metrics
  
### Table 1: Stand characteristics

Table 1 was modified to remove the sub-tables and flatted sub-tables in certain columns.

```{r table1}
#| code-fold: true
#| message: false

read_csv(file = table1.file,
                   skip = 1,
                   col_types = cols(.default = col_character())) |>
  kable(caption = read_csv(file = table1.file, 
                                 n_max = 1, col_names = 'caption', 
                                 show_col_types = FALSE)$caption)
```

### Table 3: Climate

```{r table3}
#| code-fold: true
#| message: false

read_csv(file = table3.file,
                   skip = 1,
                   col_types = cols(.default = col_character())) |>
  kable(caption = read_csv(file = table3.file, 
                                 n_max = 1, col_names = 'caption', 
                                 show_col_types = FALSE)$caption)
```


{{< include Ares2001_Methods.md >}}

<!--  # Transcription comparison
what purpose does this serve? this file does not exist in this file group -BW
This is here mostly to remind transcribers to cross check using diff the two transcripts. Let's keep this here but comment it out. -KTB
```{bash eval=FALSE}
diff Ares2001_Methods_CAG.md Ares2001_Methods.md
```
 -->
 
# Files

These files are in the Ares2001 data rescue.

- [Readme](README_Ares2001.qmd)
  + This is the primary file that documents the transcriptions and decision made during data rescue.
- [Ares2001.bib](Ares2001.bib)
  + citation for article transcribed
- [Ares2001_Methods.bib](Ares2001_Methods.bib)
  + citations for the methods section of the article
- [Ares2001_Methods.Rmd](Ares2001_Methods.Rmd)
  + methods transcribed from primary article
- [Ares2001_Table1.csv](Ares2001_Table1.csv)
  + table 1 from primary article with site descriptions
- [Ares2001_Table3.csv](Ares2001_Table3.csv)
  + table 3 from primary article with climate variables

<!--- comment out these working notes but preserve them as work done -KTB

# Working notes (KTB)

## Data Rescue Plan

- [x] describe files in human readable form inside ReadMe
- [x] description with Git issue with link
- [x] add contribution yaml
- [x] create excel sheet with Table 1 and 3
- [x] export excel table to csv
- [x] copy over methods section into markdown 
  - started, PDF doesn't copy but there is an html version which is incomplete and error ridden. Ended up with alot of retyping.
- [x] pull down citations in methods section to bib file
- [x] add in citation links to methods
- [x] cross check with second transcriber for tables and methods
- [ ] submit to independent review
- [ ] archive on SoilDRaH


## Citation notes from Methods

Below are the citation notes from the methods section.
Some citations are missing, those are noted here and how best guess were generated.

- [x] Sato et al. 1973
  + Sato, H.H., Ikeda, W., Paeth, R., Smythe, R., and Takehiro, M. 1973. Soil survey of the island of Hawaii, state of Hawaii. USDA Soil Conservation Service, University of Hawaii Agricultural Experiment Station, U.S. Government Printing Office, Washington D.C.
  + manually entered 
- [x] Harrington and Fownes (1993)
  + Harrington, R.A., and Fownes, J.H. 1993. Allometry and growth of planted versus coppice stands of four fast-growing tropical tree species. For. Ecol. Manage. 56: 315-327.
  + direct export
- [x] Sprugel 1983
  + Sprugel, D.G. 1983. Correcting for bias in log-transformed allometric equations. Ecology, 64: 209-210.
  + direct export
- [x] Avery 1975
  + Avery, T.E. 1975. Natural resources measurements. McGraw-Hill Inc., New York.
  + Manual add as a @book
- [x] Welles and Norman 1991
  + Welles, J.M., and Norman, J.M. 1991. Instrument for indirect measurement of canopy architecture. Agron. J. 83: 818-825.
  + direct export
- [x] Nelson and Sommers ~1972~ 1973
  + Nelson, D.W., and Sommers, L.E. 1972. Determination of total nitrogen in plant material. Agron. J. 65: 109-112.
  + correction to the year, 1973 instead
- [x] Isaac and Johnson 1983
  + Isaac, R.A., and Johnson, W.C. 1983. High speed analysis of agriculture samples using inductively coupled plasma-atomic emission spectroscopy. Spectrochim. Acta, 38B: 277-282.
  + direct export
- [x] Wolf 1974
  + Wolf, B. 1974. Improvements in the azomethine-H-method for the determination of boron. Comm. Soil Sci. Plant Anal. 5: 39-44.
  + direct export
- [x] Vitousek and Sanford 1986
  + Vitousek, PM., and Sanford, R.L. 1986. Nutrient cycling in moist tropical forests. Annu. Rev. Ecol. Syst. 17: 137-167.
  + direct export
  + correct number citation
- [x] Heanes 1984
  + Heanes, D. L. 1984. Determination of total organic C in soils by improved chromic acid digestion and spectrophotometric procedure. Commun. Soil Sci. Plant Anal. 15: 1191-1213.
  + direct export
--->

# Level 0 data read

This level 0 data read parses the transcribed files with minimal cleaning or transformations.

```{r readLevel0}
#This chunk has two purposes. 
#...1) Check the formatting by reading in everything 
#...2) Create a list of everything to process later in level 1

data.lvl0.df <- list(
  #Read in a list of all the bib files
  citation = list(
    #Citation for the article transcriptions are pulled from
    primary = read.bib(file = primaryCitation.file), 
    #Citations for all referenced articles
    methods = read.bib(file = methodsCitation.file)
  ),
  #Read in the text transcription of the article's methods section
  method = read_lines(file = methods.file),
  #Read in the results as tables or figure transcriptions. This includes
  #...the caption as well as the tables themselves
  data = list(
    Table1 = list(
      #Read the caption as a text string. Captions are the first cell on 
      #...the first row.
      caption = read_csv(file = table1.file,
                         col_types = cols(.default = col_character()),
                         n_max = 1, col_names = FALSE)$X1[1],
      #Read in all the data, skipping the first row with the caption and read
      #...in the table as character. This element is a tibble (data.frame).
      primary = read_csv(file = table1.file,
                         col_types = cols(.default = col_character()),
                         skip = 1)
    ), 
    #Same format as Table1
    Table3 = list(
      caption = read_csv(file = table3.file,
                         col_types = cols(.default = col_character()),
                         n_max = 1, col_names = FALSE)$X1[1],
      primary = read_csv(file = table3.file,
                         col_types = cols(.default = col_character()),
                         skip = 1)
    )))

```

# Level 1 data - Hawaii SOC DB

This data is identified as a data source for the [Hawai'i Soil Organic Carbon Database](https://osf.io/hmtv6/) as part of the HiCSC.

- Location: Location region is identified and lat/lon can likely be recovered from figure 1 by regional expert.
- Soil carbon stock: Soil carbon fraction is given but not bulk density nor coarse fraction.
- Soil type: Soil order and history are identified in methods. High/low activity clay status may need inference by regional expert.
- Land use: Land use and history are clearly identified in methods.

```{r}

#Pull in the soil type and land use from the methods section
#Pull in the soc stock from one of the tables(?)
#Check for geolocation and observation date somewhere???

#create a metadata table/df and move/paste in values from methods and citation info
data.df <- tribble(~of_variable, ~is_type, ~with_entry, ~source,
                   'region', 'value', 'Honaunau Forest on the southwestern slopes of Mauna Loa, island of Hawaii', paste('Method ln5:', paste(data.lvl0.df$method[5], collapse = ' ')),
                   'land_use_type', 'value', 'Tree stands', paste('Method ln14-16:', paste(data.lvl0.df$method[14:16], collapse = ' ')), #were these methods a manual fine?
                   'inital_planting', 'value', '1959', paste('Method ln14:', data.lvl0.df$method[14]),
                   'observation_year', 'value', '1996', paste('Method ln 30;53;58:', paste0(data.lvl0.df$method[c(30,53,58)], collapse = '... ')),
                   'citation', 'value', format(data.lvl0.df$citation$primary), 'journal citation',
                   'doi', 'value', data.lvl0.df$citation$primary$doi, 'journal citation')

#create a temporary df as temp1 using Table1 data
temp1 <- data.lvl0.df$data$Table1$primary |>
  mutate(row_id = paste0('R', 1:n())) |> #adding a row id -- not unique, preserving row source
  pivot_longer(cols = -row_id,
               names_to = 'column_name', values_to = 'with_entry', #specifying columns in the pivot to populate
               values_drop_na = TRUE) |> #drop missing values 
  mutate(of_variable = case_when( #swap human readible text (I think) depeding on value for the 'of_variable' column
           column_name == "Stand type" ~ 'stand_type',
           column_name == 'Elevation (m)' ~ 'elevation',
           column_name == 'Soil type' ~ 'soil_class',
           column_name == 'Soil pH' ~ 'soil_ph',
           column_name == 'Soil organic carbon (%)' ~ 'soil_organic_carbon',
           column_name == 'Soil N (%)' ~ 'soil_nitrogen',
           column_name == 'Soil P (mg kg<sup>-1</sup>)' ~ 'soil_phosphorus',
           column_name == 'Stand age (years)' ~ 'stand_age',
           column_name == '*F. uhdei* Stem density (trees / ha)' ~ 'stem_density_F_uhdei',
           column_name == '*F. uhdei* Mean DBH (cm)' ~ 'diameter_at_breast_height_F_uhdei',
           column_name == '*F. uhdei* Mean height(m)' ~ 'height_F_uhdei',
           column_name == '*A. koa* Stem density (trees / ha)' ~ 'stem_density_A_koa',
           column_name == '*A. koa* Mean DBH (cm)' ~ 'diameter_at_breast_height_A_koa',
           column_name == "*A. koa* Mean height(m)"~ 'height_A_koa')) |>
  mutate(source = 'Table 1') #add column called source and populate each row with Table 1.  I assume this will make sense further down :)
#View(temp1)

# creating a metadata table for temp1
temp1.meta <-
  temp1 |>
  select(column_name, of_variable) |>
  unique() |>
  mutate(unit = str_extract(column_name, pattern = '(?<=\\().*(?=\\))'), # well it's the units column with a regex pattern to....grab everything between parentheses
         source = 'Table 1 column names.') |>
  filter(!is.na(unit)) |>
  select(-column_name) |>
  bind_rows(
  tribble(~of_variable, ~method, ~source,
            'soil_ph', paste0(data.lvl0.df$method[72:73], collapse = ' '), 'Methods ln72-73', #pasting in a method from specific rows
            'soil_organic_carbon', paste0(data.lvl0.df$method[72:73], collapse = ' '), 'Methods ln72-73',
            'soil_nitrogen', paste0(data.lvl0.df$method[72:73], collapse = ' '), 'Methods ln72-73',
            'soil_phosphorus', paste0(data.lvl0.df$method[72:73], collapse = ' '), 'Methods ln72-73',
            'soil_class', paste0(data.lvl0.df$method[10:12], collapse = ' '), 'Methods ln10-12') ) |>
  bind_rows(
    tribble(~of_variable, ~control_vocabulary, ~source, #hard coding controlled vocabulary values....I think
            'stand_type', '*F. uhdei*: pure stands of Fraxinus uhdei (Wenzig) Lingelsh|Mixed: mixed stands of *Fraxinus uhdei* (Wenzig) Lingelsh and *Acacia koa* Grey', 'Abstract ln1',
            'soil_class', 'Histosol:USDA classification for histosol soil type|Andisols:USDA classification for andisol soil type', 'expert informed')
  ) |>
  # is this pivot compressing or separating?
  pivot_longer(cols = c(unit, method, control_vocabulary),
               names_to = 'is_type',
               values_drop_na = TRUE,
               values_to = 'with_entry')
#View(temp1.meta)

#the following is doing the same process as above but fitted to the data and formatting of Table3
temp3 <- data.lvl0.df$data$Table3$primary |>
  pivot_longer(cols = -variable,
               names_to = 'row_id', values_to = 'with_entry',
               values_drop_na = TRUE) |>
  #mutate(`elevation_id` = str_extract(elevation_id, '\\d{3,} m')) |>
  pivot_wider(names_from = 'variable', values_from = 'with_entry') |>
  mutate(`Elevation (m)` = str_extract(row_id, '\\d{3,}')) |>
  pivot_longer(cols = -row_id, 
               names_to = 'column_name', values_to = 'with_entry') |>
  mutate(of_variable = case_when(
    column_name == "Mean air temperature (degree C)"~ 'mean_air_temperature',
    column_name == "Total rainfall (mm)" ~ 'total_rainfall',
    column_name == "Mean total solar radiation (MJ m<sup>-2</sup> day<sup>-1</sup>)" ~ 'mean_solar_radiation',
    column_name == "Mean maximum vapor pressure deficit (kPa)" ~ 'mean_max_vapor_pressure_deficit',
    column_name == "Elevation (m)" ~ 'elevation',
    TRUE ~ NA_character_)) |>
  mutate(source = 'Table 3')

temp3.meta <- temp3 |>
  select(column_name, of_variable) |>
  unique() |>
  mutate(unit = str_extract(column_name, pattern = '(?<=\\().*(?=\\))'),
         method = paste('Methods ln72-73:', paste0(data.lvl0.df$method[18:23], collapse = ' '))) |>
  select(-column_name) |>
  pivot_longer(cols = -of_variable,
               names_to = 'is_type', values_to = 'with_entry') |>
  mutate(source = case_when(is_type == 'unit' ~ 'Table 3 column names.',
                            is_type == 'method' ~ 'Methods ln72-73',
                            TRUE ~ NA_character_))

# so this is where I get lost
# assuming I understand what's going on here....
# the info was munged as separate dfs
# but now it gets mashed into a list (well, list of lists) for all the metadata and primary data
data.lvl1.ls <- list(
  meta = bind_rows(data.df,
                   temp1.meta, 
                   temp3.meta),
  primary = bind_rows(temp1, temp3)|>
    mutate(elevation_id = with_entry[of_variable == 'elevation'],
           is_type = 'value',
           .by = row_id) |>
    arrange(row_id, elevation_id, column_name,
            of_variable, is_type, with_entry, source))
#View(data.lvl1.ls)
```


# Level 2 data

```{r}

# yep, just defining all the variables
HISOC_variables <- c(
  "citation",
  "doi",
  "region", 
  "land_use_type",
  "observation_year",
  'elevation',
  'mean_air_temperature',
  'total_rainfall',
  "soil_organic_carbon",
  "soil_nitrogen",
  "soil_phosphorus",
  "soil_ph",
  "soil_class",
  "stand_age",
  'stand_type'
)

# create a temp_study df using level1 metadata and match (or filter) to HICSC variable
temp_study <- data.lvl1.ls$meta |>
  filter(of_variable %in% HISOC_variables) |>
select(-source)  |>
  unique()|>
  pivot_wider(names_from = c(of_variable, is_type), names_sep = '::', values_from = with_entry) |>
  mutate(study_id = 'Ares2001')
  
# same as above but look for and match to specific strings-- soil or stand   
temp_plot <- data.lvl1.ls$primary|>
  filter(of_variable %in% HISOC_variables,
         str_detect(of_variable, 'soil') |
           str_detect(of_variable, 'stand'))|>
  select(-c(column_name, source)) |>
  pivot_wider(names_from = c(of_variable, is_type), names_sep = '::', values_from = with_entry) |>
  select(-row_id) |>
  mutate(study_id = 'Ares2001')

# same as above but look for and match against strings without soil or stand (should be whatever is left)
temp_evel <- data.lvl1.ls$primary|>
  filter(of_variable %in% HISOC_variables,
         !(str_detect(of_variable, 'soil') |
           str_detect(of_variable, 'stand')))|>
  select(-c(row_id, column_name, source)) |>
  unique() |>
  mutate(with_entry = as.numeric(with_entry)) |>
  pivot_wider(names_from = c(of_variable, is_type), names_sep = '::', values_from = with_entry) |>
  mutate(
    #Figure out linear interpolation with
    #lm(formula = `mean_air_temperature::value` ~ `elevation::value`, data = temp_evel)
    #N = 3, Adjusted R-squared:  0.997 , p-value: 0.02449
    
    # bw -- if no mean air temp use available data to calculate it -- where did calculated range values originate?  
    `mean_air_temperature::value` = if_else(is.na(`mean_air_temperature::value`), 23.15 - 0.006429 * `elevation::value`, `mean_air_temperature::value`), 
    #N = 3, Adjusted R-squared:  0.9886; p-value: 0.0482
    
    # bw -- same as mean air temp but now do total rainfall -- where did calculated range values originate?
    `total_rainfall::value` = if_else(is.na(`total_rainfall::value`),
                                      19078.83 - 9.97 * `elevation::value`, `total_rainfall::value`)) |>
  mutate(across(everything(), as.character)) |>
  mutate(study_id = 'Ares2001')


# join the temp dfs above together
data.lvl2.df <- full_join(temp_study,
                          temp_plot, 
                          by = join_by(study_id)) |>
  full_join(temp_evel, 
            by = join_by(elevation_id, study_id)) |>
  mutate(row_id = paste0('ID', 1:n())) |>
  pivot_longer(cols = -c(study_id, elevation_id, row_id),
               values_to = 'with_entry',
               names_sep = '::',
               names_to = c('of_variable', 'is_type'),
               values_drop_na = TRUE) 

#View(data.lvl2.df)
```


## HiCSC Visuals

```{r fig.width=7, fig.height=6}
# generating unique plots using level 2 data (obviously)
# but....I'm going to leave this for another day
plot.df <- data.lvl2.df |>
  mutate(is_type = 
           case_when(
             str_detect(with_entry, pattern = '^\\d+\\.?\\d*$') ~ paste0(is_type, '_numeric'),
             is_type == 'value' ~ paste0(is_type, '_text'),
             TRUE ~ is_type)) |>
  pivot_wider(names_from = 'is_type',
              values_from = 'with_entry') |>
  mutate(value_numeric = as.numeric(value_numeric),
         label = paste0(of_variable, ' (', unit, ')'))

ggplot(plot.df |>
         filter(is.finite(value_numeric)) )+
  geom_histogram(aes(x=value_numeric), bins = 10) +
  facet_wrap(~label, scales = 'free')

plot.df |>
  filter(!is.na(value_text)) |>
  reframe(count = n(),
    .by = c(of_variable, value_text)) |>
  arrange(of_variable, count, value_text) |>
  kbl() |>
  kable_paper()
```

# References